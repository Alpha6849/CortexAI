{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd303f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting Schema Detector Notebook...\n",
      " DataFrame not found. Loading from CSV as fallback...\n",
      " Loaded fallback dataset from: ../data/sample.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SepalLengthCm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SepalWidthCm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PetalLengthCm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PetalWidthCm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Species",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "801ad1f0-2cf4-43a0-a416-e8d04cfe4745",
       "rows": [
        [
         "0",
         "1",
         "5.1",
         "3.5",
         "1.4",
         "0.2",
         "Iris-setosa"
        ],
        [
         "1",
         "2",
         "4.9",
         "3.0",
         "1.4",
         "0.2",
         "Iris-setosa"
        ],
        [
         "2",
         "3",
         "4.7",
         "3.2",
         "1.3",
         "0.2",
         "Iris-setosa"
        ],
        [
         "3",
         "4",
         "4.6",
         "3.1",
         "1.5",
         "0.2",
         "Iris-setosa"
        ],
        [
         "4",
         "5",
         "5.0",
         "3.6",
         "1.4",
         "0.2",
         "Iris-setosa"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\" Starting Schema Detector Notebook...\")\n",
    "\n",
    "\n",
    "# Check if the notebook is being run after Notebook 01\n",
    "try:\n",
    "    df  # Check if df already exists\n",
    "    print(\" Using DataFrame from previous notebook.\")\n",
    "    current_df = df\n",
    "except NameError:\n",
    "    print(\" DataFrame not found. Loading from CSV as fallback...\")\n",
    "    \n",
    "    # Fallback: load CSV again\n",
    "    fallback_path = \"../data/sample.csv\"\n",
    "    current_df = pd.read_csv(fallback_path)\n",
    "    print(f\" Loaded fallback dataset from: {fallback_path}\")\n",
    "\n",
    "\n",
    "current_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "979d65d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Corrected Column Type Detection:\n",
      "{'numeric': ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'], 'categorical': ['Species'], 'boolean': [], 'datetime': []}\n"
     ]
    }
   ],
   "source": [
    "# Detect numeric, categorical, boolean, and datetime columns (fixed logic)\n",
    "\n",
    "def detect_column_types(df):\n",
    "    \"\"\"\n",
    "    Automatically detects schema types in the dataset.\n",
    "    Returns a dictionary of column categories.\n",
    "    \"\"\"\n",
    "\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    boolean_cols = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "\n",
    "    # Datetime detection ONLY for object/string columns\n",
    "    datetime_cols = []\n",
    "    for col in categorical_cols:\n",
    "        try:\n",
    "            parsed = pd.to_datetime(df[col], errors='raise')\n",
    "            datetime_cols.append(col)\n",
    "        except:\n",
    "            pass  # Not datetime\n",
    "\n",
    "    # Remove datetime columns from categorical list\n",
    "    categorical_cols = [c for c in categorical_cols if c not in datetime_cols]\n",
    "\n",
    "    schema = {\n",
    "        \"numeric\": numeric_cols,\n",
    "        \"categorical\": categorical_cols,\n",
    "        \"boolean\": boolean_cols,\n",
    "        \"datetime\": datetime_cols\n",
    "    }\n",
    "\n",
    "    print(\" Corrected Column Type Detection:\")\n",
    "    print(schema)\n",
    "\n",
    "    return schema\n",
    "\n",
    "\n",
    "# Run schema detection again\n",
    "schema = detect_column_types(current_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862a31d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ID-like Columns Detected: ['Id', 'SepalWidthCm', 'PetalWidthCm']\n"
     ]
    }
   ],
   "source": [
    "# Detect ID-like columns (not useful just causes overfitting , ig treating them like class roll no might help imo , doesnt tell shit about student)\n",
    "\n",
    "def detect_id_columns(df):\n",
    "    \"\"\"\n",
    "    Detects columns that behave like ID columns:\n",
    "    - unique for each row\n",
    "    - or name contains 'id'\n",
    "    \"\"\"\n",
    "\n",
    "    n_rows = len(df)\n",
    "\n",
    "    id_candidates = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        # Rule 1: Unique for every row â†’ strong ID\n",
    "        if df[col].nunique() == n_rows:\n",
    "            id_candidates.append(col)\n",
    "            continue\n",
    "        \n",
    "        # Rule 2: Column name contains 'id'\n",
    "        if \"id\" in col.lower():\n",
    "            id_candidates.append(col)\n",
    "\n",
    "    print(\" ID-like Columns Detected:\", id_candidates)\n",
    "    return id_candidates\n",
    "\n",
    "\n",
    "# Run ID detection\n",
    "id_cols = detect_id_columns(current_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b8bc05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Possible Target Columns: ['Species']\n"
     ]
    }
   ],
   "source": [
    "# Detect potential target column (mostly one with less <30 unique values or last columm -- like in mcq exams u guess it base unique options)\n",
    "\n",
    "def detect_target_column(df, id_cols):\n",
    "    \"\"\"\n",
    "    Automatically identifies the most likely target column.\n",
    "    \"\"\"\n",
    "\n",
    "    target_candidates = []\n",
    "\n",
    "    for col in df.columns:\n",
    "\n",
    "        # Skip ID columns (never targets)\n",
    "        if col in id_cols:\n",
    "            continue\n",
    "\n",
    "        # Rule 1: If unique values are small, good for classification\n",
    "        if df[col].nunique() <= 30 and df[col].dtype == 'object':\n",
    "            target_candidates.append(col)\n",
    "\n",
    "    # Rule 2: fallback - last column\n",
    "    if len(target_candidates) == 0:\n",
    "        target_candidates.append(df.columns[-1])\n",
    "\n",
    "    print(\" Possible Target Columns:\", target_candidates)\n",
    "    return target_candidates\n",
    "\n",
    "\n",
    "# Run target detection\n",
    "target_cols = detect_target_column(current_df, id_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7421d3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Low-variance columns (>99.0% same value): []\n"
     ]
    }
   ],
   "source": [
    "# Detect low-variance columns (cols with 99% same values , so just remove them cause nothing to learn)\n",
    "\n",
    "def detect_low_variance_columns(df, threshold=0.99):\n",
    "    \"\"\"\n",
    "    Identifies columns where one value dominates (low variance).\n",
    "    threshold = percentage of most common value allowed.\n",
    "    \"\"\"\n",
    "\n",
    "    low_var_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        top_frequency = df[col].value_counts(normalize=True).max()\n",
    "        \n",
    "        if top_frequency >= threshold:\n",
    "            low_var_cols.append(col)\n",
    "\n",
    "    print(f\" Low-variance columns (>{threshold*100}% same value): {low_var_cols}\")\n",
    "    return low_var_cols\n",
    "\n",
    "\n",
    "# Run low-variance detection\n",
    "low_var_cols = detect_low_variance_columns(current_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5646bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Schema Object:\n",
      "numeric_columns: ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
      "categorical_columns: ['Species']\n",
      "boolean_columns: []\n",
      "datetime_columns: []\n",
      "id_columns: ['Id', 'SepalWidthCm', 'PetalWidthCm']\n",
      "target_candidates: ['Species']\n",
      "low_variance_columns: []\n",
      "n_rows: 150\n",
      "n_columns: 6\n"
     ]
    }
   ],
   "source": [
    "# Combine everything into one final schema dictionary\n",
    "\n",
    "def build_schema_object(df, schema, id_cols, target_cols, low_var_cols):\n",
    "    \"\"\"\n",
    "    Creates a unified schema dictionary containing all detected metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    final_schema = {\n",
    "        \"numeric_columns\": schema[\"numeric\"],\n",
    "        \"categorical_columns\": schema[\"categorical\"],\n",
    "        \"boolean_columns\": schema[\"boolean\"],\n",
    "        \"datetime_columns\": schema[\"datetime\"],\n",
    "        \"id_columns\": id_cols,\n",
    "        \"target_candidates\": target_cols,\n",
    "        \"low_variance_columns\": low_var_cols,\n",
    "        \"n_rows\": df.shape[0],\n",
    "        \"n_columns\": df.shape[1]\n",
    "    }\n",
    "\n",
    "    print(\" Final Schema Object:\")\n",
    "    for key, value in final_schema.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    return final_schema\n",
    "\n",
    "\n",
    "# Build final schema using all detection functions\n",
    "final_schema = build_schema_object(\n",
    "    current_df,\n",
    "    schema,\n",
    "    id_cols,\n",
    "    target_cols,\n",
    "    low_var_cols\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca2b90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Step 1: Detecting basic column types...\n",
      " Corrected Column Type Detection:\n",
      "{'numeric': ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'], 'categorical': ['Species'], 'boolean': [], 'datetime': []}\n",
      "\n",
      " Step 2: Detecting ID-like columns...\n",
      " ID-like Columns Detected: ['Id', 'SepalWidthCm', 'PetalWidthCm']\n",
      "\n",
      " Step 3: Detecting target column(s)...\n",
      " Possible Target Columns: ['Species']\n",
      "\n",
      " Step 4: Detecting low-variance columns...\n",
      " Low-variance columns (>99.0% same value): []\n",
      "\n",
      " Step 5: Building final schema object...\n",
      " Final Schema Object:\n",
      "numeric_columns: ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
      "categorical_columns: ['Species']\n",
      "boolean_columns: []\n",
      "datetime_columns: []\n",
      "id_columns: ['Id', 'SepalWidthCm', 'PetalWidthCm']\n",
      "target_candidates: ['Species']\n",
      "low_variance_columns: []\n",
      "n_rows: 150\n",
      "n_columns: 6\n",
      "\n",
      " Schema Detection Complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'numeric_columns': ['Id',\n",
       "  'SepalLengthCm',\n",
       "  'SepalWidthCm',\n",
       "  'PetalLengthCm',\n",
       "  'PetalWidthCm'],\n",
       " 'categorical_columns': ['Species'],\n",
       " 'boolean_columns': [],\n",
       " 'datetime_columns': [],\n",
       " 'id_columns': ['Id', 'SepalWidthCm', 'PetalWidthCm'],\n",
       " 'target_candidates': ['Species'],\n",
       " 'low_variance_columns': [],\n",
       " 'n_rows': 150,\n",
       " 'n_columns': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Master function to run full schema detection pipeline\n",
    "\n",
    "def generate_schema(df):\n",
    "    \"\"\"\n",
    "    Runs the complete schema detection pipeline and returns a full schema dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\" Step 1: Detecting basic column types...\")\n",
    "    schema = detect_column_types(df)\n",
    "\n",
    "    print(\"\\n Step 2: Detecting ID-like columns...\")\n",
    "    id_cols = detect_id_columns(df)\n",
    "\n",
    "    print(\"\\n Step 3: Detecting target column(s)...\")\n",
    "    target_cols = detect_target_column(df, id_cols)\n",
    "\n",
    "    print(\"\\n Step 4: Detecting low-variance columns...\")\n",
    "    low_var_cols = detect_low_variance_columns(df)\n",
    "\n",
    "    print(\"\\n Step 5: Building final schema object...\")\n",
    "    final_schema = build_schema_object(df, schema, id_cols, target_cols, low_var_cols)\n",
    "\n",
    "    print(\"\\n Schema Detection Complete!\")\n",
    "    return final_schema\n",
    "\n",
    "\n",
    "# Run full schema pipeline on the dataset\n",
    "full_schema = generate_schema(current_df)\n",
    "full_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320867f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
